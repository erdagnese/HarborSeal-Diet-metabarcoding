---
title: "04-Amplification_bias_correction"
author: "Erin D'Agnese"
date: "2025-02-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script is used after tourmaline-decontamination and ASV-taxon to correct reads based on amplification bias using the model and mock community sequencing. 

it requires:
1. QAQC of the mock community metadata - need to compile the metadata for all the Mocks then format the metadata like this but we only need to carry over the mass since for our mocks we made the mocks based on total DNA in anyway rather than needing to calc from ng/ul:

Species Barcode	Community	DNA_Ratio	DNA_conc_ng_uL	Total_DNA	
Citharichthys	sordidus	12S	Skew_Oceanic_1	6	18	108
Citharichthys	stigmaeus	12S	Skew_Oceanic_1	1	18	18
Citharichthys	xanthostigma	12S	Skew_Oceanic_1	1	18	18
Engraulis	mordax	12S	Skew_Oceanic_1	1	18	18
Leuroglossus	stilbius	12S	Skew_Oceanic_1	1	18	18
Merluccius	productus	12S	Skew_Oceanic_1	1	18	18
Nannobrachium	ritteri	12S	Skew_Oceanic_1	1	18	18
Sardinops	sagax	12S	Skew_Oceanic_1	6	18	108

2. QAQC mock sequence data so that we can join them to create a mock_community_data.rds that looks like this:
# A tibble: 6 Ã— 6
  ID_mifish community    tech_rep Cycles nReads start_conc_ng
  <chr>     <chr>        <chr>    <chr>   <dbl>         <int>
1 Agonidae  Coastal_Even 1        30          0             0
2 Agonidae  Coastal_Even 1        33          0             0
3 Agonidae  Coastal_Even 1        36          0             0
4 Agonidae  Coastal_Even 1        39          0             0
5 Agonidae  Coastal_Even 2        30          0             0
6 Agonidae  Coastal_Even 2        33          0             0

3. the mock community model calibration using mock_community_data.rds and 

(For 18S and MiFish it was 39 cycles including the 14 TD cycles)

Notes from Zack:
We need to put in sanity checks to look at the stacked barplots of proportions 

For big skate and ratfish - if there are things in one rep of the mock but not in the others then they need to be removed 

In the Mock: Take the species that showed up in all the technical reps only and throw them out cuz it breaks the model 
Make a mock for the shrimp - take the alpha at the end and hard code

Filter observed for those species - drop any samples that have low reads (ZG did <5000 for 5 species) 

Run the TM and Ctrl as observed - may need to separate them, but shouldn't need to

Plot what they look like before and after for both mock and obsevered to make sure nothing weird is happening. 

Try it step-wise adding rather than removing - pare the mock down to the most important, get the model to run and then add more species in until it stops work

To do: 
DONE - Check the tissue mixtures for the cephalopods - may need to merge them all, not sure assignment is actually working beyond cephalopods, then we would need to alter the mock community props as well.

Run the wild samples through the new classifiers and final_taxonomy and decontam scripts and then pull them in to subset only samples with high prop of reads to prey

First let's load the packages for formatting the mock community data 
```{r}
library(here)
library(tidyverse)
```

load in the metadata for the mock community data
```{r}
mock_data <- read.csv(here("input-files","Mock_communities_18S_metadata.csv"), header=T, check.names = FALSE)
```
There is more columns than we need so let's clean that dataframe up - the start_conc_ng in Zack's input is actual total DNA so will just use the mass_ng since they are the same type of "conc"
```{r}
mock_data %>% 
  rename(taxon_assign = "18S_taxon_assign") %>% 
  rename(species = "Species") %>% 
  select(species,taxon_assign, Community, Even_prop, Even_mass_ng, SK1_prop, SK1_mass_ng, SK2_prop, SK2_mass_ng) -> mock_data

```

Let's clean up the mock data of the species that are causing issues for model fit
```{r}
#let's remove Nereididae abd the lamprey because they seem to be causing problems in the model and aren't that prevelant in the diet, plus we can use the TM if we need to, Neotrypaea may also be a problem in the combined data
mock_data %>% 
  filter(taxon_assign != "Nereididae") %>% 
  filter(taxon_assign != "Lampetra fluviatilis") %>% 
  #filter(taxon_assign != "Neotrypaea") %>% 
  filter(taxon_assign != "Chimaeridae") -> mock_data
```

we need to make it longform with a specific name for each community that matches the samplenames in the sequencing metadata
```{r}
library(tidyverse)
long_mock_data <- mock_data %>%
  # Select relevant columns (excluding species name)
  select(taxon_assign, Community, ends_with("_mass_ng")) %>%
  # Pivot to long format
  pivot_longer(
    cols = ends_with("_mass_ng"),
    names_to = "sample_type",
    values_to = "start_conc_ng"
  ) %>%
  # Clean up sample type names and create community IDs
  mutate(
    sample_type = str_remove(sample_type, "_mass_ng"),
    community = paste(Community, sample_type, sep = "_")
  ) %>%
  rename(
    ID_18S = taxon_assign
  ) %>%
  # Remove original Community column (now in community)
  select(-Community) %>%
  # Group by ID_18S and community to sum concentrations
  group_by(ID_18S, community) %>%
  summarise(
    start_conc_ng = sum(start_conc_ng, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Remove any zero-concentration entries
  filter(start_conc_ng > 0) %>%
  # Sort for clean output
  arrange(community, ID_18S)

# First fix the naming in long_mock_data
long_mock_data <- long_mock_data %>%
  mutate(
    community = case_when(
      str_detect(community, "_SK1") ~ str_replace(community, "_SK1", "_Skew_1"),
      str_detect(community, "_SK2") ~ str_replace(community, "_SK2", "_Skew_2"),
      TRUE ~ community  # Keep other names unchanged
    )
  )

# View result
head(long_mock_data)
```

okay we need the Mock community sequencing data now and we need to modify the names of the collumns and clean up the rows and taxonomy
```{r}
asv_data <- read.csv(here("intermediate-files","CorrectionBiasRun","CorBias_18S_taxon_decontam_asv_table.csv"), header = T, check.names = F)

asv_meta <- read.table(here("data","CorrectionBias","tourmaline-CorBias_18S_16072025","00-data","metadata.tsv"), sep = "\t", header = T)

asv_wild_data <- read.csv(here("intermediate-files", "Wild_CB_Samples", "Wild_CB2_18S_taxon_decontam_asv_table.csv"), header = T, check.names = F)


wild_md3 <- read.csv(here("input-files","FULL_CBrun2_metadata.csv"), header = T)
```



I've modified the calibration function so eventually should be able to just call this and run it... stay tuned
```{r}
source(here("scripts","calibrate_metabarcoding.R"))
```



let's select out the mock community samples 
```{r}
asv_meta %>% 
  filter(region == "MockCom") -> mock_asv_meta

# First, get the sample IDs you want to keep from the metadata
samples_to_keep <- mock_asv_meta$sampleid

# Convert the ASV table to long format and filter for desired samples
filtered_asv_data <- asv_data %>%
  # Keep the taxonomy column
  select(final_taxonomy, all_of(samples_to_keep)) %>%
  # Convert to long format
  pivot_longer(
    cols = -final_taxonomy,
    names_to = "sampleid",
    values_to = "count"
  ) %>%
  # Filter to only include samples in your metadata
  filter(sampleid %in% samples_to_keep)

# The result is a long-format dataframe with taxonomy, sampleid, and count columns
head(filtered_asv_data)

mock_asv_data <- filtered_asv_data %>%
  left_join(mock_asv_meta, by = "sampleid")

```

now we need to clean up the data based on the known input species and remove any contaminants that are secondary prey from the species that we homogenized
```{r}
mock_asv_data <- mock_asv_data %>%
  # First separate samplename into all components
  separate(
    samplename,
    into = c("sampletype", "marker", "commtype", "commmix", "tech"),
    sep = "_",
    remove = FALSE
  ) %>%
  # Clean up technical replicates
  mutate(
    tech = as.integer(str_remove(tech, "^R")),  # Remove "R" and convert to integer
    # Reconstruct community name without tech rep
    community = paste(sampletype, marker, commtype, commmix, sep = "_")
  )

mock_asv_data <- mock_asv_data %>%
  # Standardize Skew naming in all relevant columns
  mutate(
    across(c(community, commmix, samplename),
    ~case_when(
      str_detect(.x, "Skew1") ~ str_replace(.x, "Skew1", "Skew_1"),
      str_detect(.x, "Skew2") ~ str_replace(.x, "Skew2", "Skew_2"),
      TRUE ~ .x
    )
  )) %>%
  # Final cleanup
  select(-sampletype, -marker) %>%  # Remove temporary columns if not needed
  # Filter for present taxa
  group_by(final_taxonomy) %>% 
  filter(any(count > 0)) %>%
  ungroup()

# First get all unique ID_18S values we need to match
ids_to_match <- unique(long_mock_data$ID_18S)

# Create a list of taxonomy strings that contain any ID_18S
valid_taxa <- mock_asv_data %>%
  filter(str_detect(final_taxonomy, paste(ids_to_match, collapse = "|"))) %>%
  pull(final_taxonomy) %>%
  unique()

# Filter and merge
merged_data_rep_fish <- mock_asv_data %>%
  filter(final_taxonomy %in% valid_taxa) %>%
  inner_join(long_mock_data, by = "community") %>%
  filter(str_detect(final_taxonomy, ID_18S)) %>%
  filter(commtype == "RepFish") %>% 
  mutate(
    community = paste(commtype, commmix, sep = "_")  # Combine commtype and commmix
  )

merged_data_comb_fish <- mock_asv_data %>%
  filter(final_taxonomy %in% valid_taxa) %>%
  inner_join(long_mock_data, by = "community") %>%
  filter(str_detect(final_taxonomy, ID_18S)) %>%
  filter(commtype == "CombFish") %>% 
  mutate(
    community = paste(commtype, commmix, sep = "_")  # Combine commtype and commmix
  )

```
this removed the ratfish because nothing assigned to chimaeriformes in the 18S mocks - there is not a good 18S reference seq for ratfish and apparently it is different enough from the other chondricthyes that it won't even assign to that clade.

Let's do a sanity check- barplot of existing props of all species in each mock
```{r}
# Example usage:
p1 <- plot_taxonomy_proportions(merged_data_comb_fish, 
                               plot_title = "Initial Mock Check")

print(p1)
```
Okay that looks pretty normal for the combined fish mocks

Now the RepFish one
```{r}
p2 <- plot_taxonomy_proportions(merged_data_rep_fish, 
                               plot_title = "Initial Mock Check")

print(p2)
```

The rep fish also looks appropriate based on what we expect for the Rep fish mocks.

Reference these when comparing the versions that are transformed along the way to make sure the numbers don't get changed incorrectly.

Okay, now we also need to clean up the ASV tables of real-world sequence data. We will use the tissue mixture samples, the controlled feeding study and pull some commencement bay data as wild samples to ensure it works across all the sample types. 
```{r}
asv_meta %>% 
  filter(str_detect(Plate_ID,"Prey18S")) %>% 
  filter(region %in% c("ControlFeeding","TissueMix")) -> asv_meta_18S_samples

# First, get the sample IDs you want to keep from the metadata
samples_to_keep <- asv_meta_18S_samples$sampleid
# Find which samples_to_keep actually exist in asv_data
existing_samples <- intersect(samples_to_keep, names(asv_data))

# Convert the ASV table to long format and filter for desired samples
filtered_asv_data <- asv_data %>%
  # Keep the taxonomy column
  select(final_taxonomy, all_of(existing_samples)) %>%
  # Convert to long format
  pivot_longer(
    cols = -final_taxonomy,
    names_to = "sampleid",
    values_to = "count"
  ) %>%
  # Filter to only include samples in your metadata
  filter(sampleid %in% existing_samples)

# The result is a long-format dataframe with taxonomy, sampleid, and count columns
head(filtered_asv_data)

samples18S_asv_data <- filtered_asv_data %>%
  left_join(asv_meta_18S_samples, by = "sampleid") %>% 
  select(samplename,region,final_taxonomy,count)

```


wild samples data formatting
```{r}
asv_wild_long <- asv_wild_data %>%
  pivot_longer(
    cols = -final_taxonomy,
    names_to = "sampleid",
    values_to = "count"
  )

asv_wild_long_md <- asv_wild_long %>%
  left_join(wild_md3, by = "sampleid") 
  

asv_wild_long_md <- asv_wild_long_md %>% 
  select(Sample_ID, tech, Collection_Location, biol, date, date_numeric,final_taxonomy,count) %>% 
  filter(Collection_Location != "ControlSample") %>% 
  mutate(creek = "PvScat") 

```

Okay now we need to get the mock dataframe with all the mocks in one with different station ids


Now we need to save the cleaned up mock data as an .RDS so we can bring it in for the mock calibration step
```{r}
#Using the RepFish mock first

merged_data_rep_fish %>% 
  select(ID_18S, community, tech, count,start_conc_ng) %>% 
  mutate(Cycles = 39) %>% 
  rename("nReads" = "count") -> mock_18S_RF_input

input_mock_RFcomm <- mock_18S_RF_input %>% 
  filter(., Cycles ==39) %>% 
  group_by(community, tech) %>% 
  mutate(., totReads=sum(nReads),
         propReads = nReads/totReads,
         tot_start = sum(start_conc_ng),
         start_prop=start_conc_ng/tot_start) %>% 
  dplyr::select(Community=community, Tech_Rep=tech,species=ID_18S, nReads,totReads,propReads,start_prop, N_pcr_mock=Cycles) %>% 
  mutate(Tech_Rep = as.numeric(Tech_Rep),
         N_pcr_mock = as.numeric(N_pcr_mock)) 

input_mock_RFcomm %>% 
  rename(tech = Tech_Rep) %>% 
  group_by(Community) %>%
  mutate(station_idx = cur_group_id()) %>%
  ungroup() %>% 
  mutate(station = station_idx) -> input_mock_RFcomm_RDS

#save for future use
saveRDS(input_mock_RFcomm, here("intermediate-files","Prey18S_RepFish_mock_community_data.RDS") )

#and now the CombFish
merged_data_comb_fish %>% 
  select(ID_18S, community, tech, count,start_conc_ng) %>% 
  mutate(Cycles = 39) %>% 
  rename("nReads" = "count") -> mock_18S_CF_input

input_mock_CFcomm <- mock_18S_CF_input %>% 
  filter(., Cycles ==39) %>% 
  group_by(community, tech) %>% 
  mutate(., totReads=sum(nReads),
         propReads = nReads/totReads,
         tot_start = sum(start_conc_ng),
         start_prop=start_conc_ng/tot_start) %>% 
  dplyr::select(Community=community, Tech_Rep=tech,species=ID_18S, nReads,totReads,propReads,start_prop, N_pcr_mock=Cycles) %>% 
  mutate(Tech_Rep = as.numeric(Tech_Rep),
         N_pcr_mock = as.numeric(N_pcr_mock)) 

input_mock_CFcomm %>% 
  rename(tech = Tech_Rep) %>% 
  group_by(Community) %>%
  mutate(station_idx = cur_group_id()) %>%
  ungroup() %>% 
  mutate(station = station_idx) -> input_mock_CFcomm_RDS

#save for future use
saveRDS(input_mock_CFcomm, here("intermediate-files","Prey18S_CombFish_mock_community_data.RDS") )

#we are going to us the input_mock_RFcomm and input_mock_CFcomm in the combine

input_mock_CFcomm <- readRDS(here("intermediate-files","Prey18S_CombFish_mock_community_data.RDS"))
```

Now the mock data should be ready to input in the model calibration, but let's make sure the prop calc outputs worked as expected compared to the previous figure 

```{r}
# Example usage:
p3 <- plot_proportion_comparison(input_mock_RFcomm_RDS,existing_prop_col = "propReads",
                                 plot_title = "Count vs Existing Proportions")
print(p3)
```
They look correct

```{r}
p4 <- plot_proportion_comparison(input_mock_CFcomm_RDS,existing_prop_col = "propReads",
                                 plot_title = "Count vs Existing Proportions")
print(p4)
```
The combined fish also look the same, so we can believe we are sane still.



Create the additional mock for the Penaeus in the controlled feeding study
```{r, extract taxon function}
# Function to extract final taxon
extract_final_taxon <- function(full_taxonomy) {
  # Split by semicolon and remove empty elements
  taxa_levels <- str_split(full_taxonomy, ";")[[1]] %>% 
    str_trim() %>% 
    .[. != ""]
  
  # Work backwards through the taxonomy levels
  for (i in length(taxa_levels):1) {
    current_taxon <- taxa_levels[i]
    # Skip if the taxon is NA or empty
    if (!is.na(current_taxon) && current_taxon != "NA" && current_taxon != "") {
      return(current_taxon)
    }
  }
  
  # If all levels are NA/empty, return NA
  return(NA_character_)
}

```

This chunk is for using TM as mocks - didn't work very well at all.

pull out the mixtures we want to include as mocks
```{r}
samples18S_asv_data %>% 
  filter(region == "TissueMix") -> samples_TM_asv_data

# 1. Process the sample data to extract species names
samples_processed <- samples_TM_asv_data %>%
  mutate(
    species = map_chr(final_taxonomy, extract_final_taxon),
    species = str_trim(species)
  ) %>%
  filter(!is.na(species), species != "")

# 2. Create mock sample mapping (updated with your actual mock patterns)
mock_sample_mapping <- samples_TM_asv_data %>%
  dplyr::select(samplename) %>%
  distinct() %>%
  mutate(
    Community = case_when(
      str_detect(samplename, "BlkTigShrVAQ") ~ "TM_BlkTigShrVAQ",
      # Add more patterns based on your actual sample names
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(Community))

# 3. Build the additional_mock table
additional_mock <- samples_processed %>%
  # Join to assign Community names to each sample
  left_join(mock_sample_mapping, by = "samplename") %>%
  filter(!is.na(Community)) %>% # Keep only samples assigned to a mock
  # Group by sample and species to sum counts from different ASVs of the same species
  group_by(Community, samplename, species) %>%
  summarise(nReads = sum(count), .groups = 'drop') %>%
  # Assign tech replicate number based on samplename (e.g., 01 -> 1, 02 -> 2)
  mutate(Tech_Rep = as.integer(str_extract(samplename, "(?<=_)\\d+(?=_)"))) %>%
  # Define the TRUE input composition for each mock community
  # You'll need to fill this in with the actual concentrations for your mocks
  mutate(
    start_conc_ng = case_when(
      Community == "TM_BlkTigShrVAQ" & species == "Penaeus monodon" ~ 0.5,
      Community == "TM_BlkTigShrVAQ" & species == "Actinopteri" ~ 0.5,
      TRUE ~ 0 # Everything else was not added to the mock
    )
  ) %>%
  filter(start_conc_ng > 0) %>% # Remove species not actually in the mock design
  # Group by Community and tech rep to calculate proportions and totals
  group_by(Community, Tech_Rep) %>%
  mutate(
    N_pcr_mock = 39, # Set the correct number of PCR cycles for these runs
    totReads = sum(nReads),
    propReads = nReads / totReads,
    tot_start_ng = sum(start_conc_ng),
    start_prop = start_conc_ng / tot_start_ng
  ) %>%
  ungroup() %>%
  # Select and finalize columns to match the input_mock_CFcomm structure
  dplyr::select(
    Community,
    Tech_Rep,
    species,
    nReads,
    totReads,
    propReads,
    start_prop,
    N_pcr_mock
  )


#saveRDS(additional_mock, here("intermediate-files","Prey18S_TMPenMock_data.RDS"))

```

Now we can combine all the mocks
```{r}
# 4. Combine all mock data
combined_mock3 <- bind_rows(
  input_mock_CFcomm,
  input_mock_RFcomm
) %>%
  arrange(Community, Tech_Rep, species)

# use one mock
combined_mock <- input_mock_CFcomm %>%
  arrange(Community, Tech_Rep, species)

# View the result
print(combined_mock, n = 20)


# 2. CRITICAL: Create the station_mapping for the combined mock
# The format_metabarcoding_data function uses this to map station numbers to names.
# It expects a dataframe with columns 'stationname' and 'station'
combined_station_mapping <- data.frame(
  stationname = unique(combined_mock$Community),
  station = as.integer(factor(unique(combined_mock$Community)))
)

# 3. Check the results
print("Unique communities and their assigned station numbers:")
print(combined_station_mapping)

print("Unique species in combined mock:")
print(unique(combined_mock$species))

# Add station mapping with exact column names
combined_mock2 <- combined_mock %>%
  left_join(combined_station_mapping, by = c("Community" = "stationname")) %>%
  rename(tech = Tech_Rep) %>%  # Rename to match your example
  dplyr::select(
    Community,
    tech,
    species,
    nReads,
    totReads,
    propReads,
    start_prop,
    N_pcr_mock,
    station_idx = station,  # station becomes station_idx
    station = station       # and also station
  ) %>%
  arrange(station_idx, tech, species)

# View the result
print(combined_mock2, n = 20)



saveRDS(combined_mock2, here("intermediate-files","input_Prey18S_combined_mockBoth_data.RDS"))

```

Now clean up data to only include taxa that are in the mock or related to things in the mock

```{r}
# Run the transformation
sample_data <- modified_sample_data(samples18S_asv_data)

# Verify the transformation
head(sample_data)

```
let's get the wild samples in the same format so we can do the next steps for both datasets and then clean up only samples with enough reads
```{r}
asv_wild_long_md %>% 
  dplyr::rename("samplename" = "Sample_ID") %>% 
  dplyr::rename("Nreads" = "count") %>% 
  dplyr::rename("station" = "Collection_Location") %>% 
  dplyr::rename("time" = "date_numeric") %>% 
  mutate(species = map_chr(final_taxonomy, extract_final_taxon),
         species = str_trim(species)) %>% 
  select(samplename,time,creek,station,biol,tech,species,Nreads) -> wild_sample_data

sample_data %>% 
  mutate(species = map_chr(species, extract_final_taxon),
         species = str_trim(species)) -> sample_data
```

We need to filter the samples based on the species and reads to the species present in the sample that match the ones in the mock
```{r}
library(tidyverse)

analyze_mock_species_in_samples <- function(sample_df, combined_mock_data) {
  # Get unique species from combined mock data
  mock_species <- unique(combined_mock_data$species)
  
  # First, get the creek information for each sample (assuming it's consistent per samplename)
  sample_creek_info <- sample_df %>%
    distinct(samplename, creek)
  
  # Sum reads by sample and species for mock species only
  mock_reads_by_sample <- sample_df %>%
    filter(species %in% mock_species) %>%
    group_by(samplename, species) %>%
    summarise(species_reads = sum(Nreads), .groups = 'drop')
  
  # Pivot wider to get one column per mock species
  mock_species_wide <- mock_reads_by_sample %>%
    pivot_wider(
      names_from = species, 
      values_from = species_reads, 
      values_fill = 0
    )
  
  # Calculate total metrics for each sample
  sample_totals <- sample_df %>%
    group_by(samplename) %>%
    summarise(
      total_reads = sum(Nreads),
      total_mock_sp_reads = sum(Nreads[species %in% mock_species]),
      prop_mock_reads = total_mock_sp_reads / total_reads,
      .groups = 'drop'
    )
  
  # Combine the wide format mock species with the total metrics and creek info
  sample_metrics <- sample_totals %>%
    left_join(mock_species_wide, by = "samplename") %>%
    left_join(sample_creek_info, by = "samplename") %>%
    # Replace NA with 0 for any mock species columns that might be missing
    mutate(across(any_of(mock_species), ~ replace_na(., 0)))
  
  # Calculate n_mock_species based on columns with reads > 0
  sample_metrics <- sample_metrics %>%
    rowwise() %>%
    mutate(
      n_mock_species = sum(c_across(any_of(mock_species)) > 0)
    ) %>%
    ungroup() %>%
    # Reorder columns to put creek in a useful position
    select(samplename, creek, total_reads, n_mock_species, total_mock_sp_reads, prop_mock_reads, everything()) %>%
    arrange(desc(prop_mock_reads))
  
  return(sample_metrics)
}


# Usage example:
sample_metrics <- analyze_mock_species_in_samples(sample_data, combined_mock2)
wild_sample_metrics <- analyze_mock_species_in_samples(wild_sample_data, combined_mock2)

# View the results
print(sample_metrics, n = 20)
print(wild_sample_metrics, n = 20)

# You can also create a summary to help with filtering decisions
summary_stats <- function(metrics_df) {
  metrics_df %>%
    summarise(
      n_samples = n(),
      avg_prop_mock = mean(prop_mock_reads),
      median_prop_mock = median(prop_mock_reads),
      min_prop_mock = min(prop_mock_reads),
      max_prop_mock = max(prop_mock_reads),
      avg_mock_species = mean(n_mock_species),
      median_mock_species = median(n_mock_species)
    )
}

# Get summary statistics
sample_summary <- summary_stats(sample_metrics)
wild_sample_summary <- summary_stats(wild_sample_metrics)

print(sample_summary)
print(wild_sample_summary)


# You can also create visualizations to help choose thresholds
plot_mock_metrics <- function(metrics_df, title = "Sample Metrics") {
  p1 <- ggplot(metrics_df, aes(x = prop_mock_reads)) +
    geom_histogram(bins = 30, fill = "lightblue", color = "black") +
    labs(title = paste(title, "- Proportion of Mock Reads"),
         x = "Proportion of reads from mock species", y = "Count")
  
  p2 <- ggplot(metrics_df, aes(x = n_mock_species)) +
    geom_histogram(bins = 30, fill = "lightgreen", color = "black") +
    labs(title = paste(title, "- Number of Mock Species"),
         x = "Number of mock species detected", y = "Count")
  
  p3 <- ggplot(metrics_df, aes(x = total_reads, y = prop_mock_reads)) +
    geom_point(alpha = 0.6) +
    labs(title = paste(title, "- Reads vs Mock Proportion"),
         x = "Total reads", y = "Proportion of mock reads")
  
  return(list(prop_plot = p1, species_plot = p2, scatter_plot = p3))
}

# Create plots to visualize the distributions
sample_plots <- plot_mock_metrics(sample_metrics, "Controlled Samples")
wild_sample_plots <- plot_mock_metrics(wild_sample_metrics, "Wild Samples")

# View the plots
print(sample_plots$prop_plot)
print(sample_plots$species_plot)
print(sample_plots$scatter_plot)

print(wild_sample_plots$prop_plot)
print(wild_sample_plots$species_plot)
print(wild_sample_plots$scatter_plot)
```

Alright, let's only keep the good samples to run the model on to start
```{r}
filter_samples_by_mock_content <- function(metrics_df, creek_filter = NULL,
                                          min_prop_mock = 0.5, min_mock_species = 2,
                                          min_total_reads = 1000) {
  
  filtered_metrics <- metrics_df %>%
    {if(!is.null(creek_filter)) filter(., creek == creek_filter) else .} %>%
    filter(prop_mock_reads >= min_prop_mock,        # Corrected column name
           n_mock_species >= min_mock_species,      # Corrected column name
           total_reads >= min_total_reads)          # Correct column name
  
  return(filtered_metrics)
}

# Your main function stays the same
filter_sample_data_by_metrics <- function(sample_df, metrics_df, creek_filter = NULL,
                                         min_prop_mock = 0.5, min_mock_species = 2,
                                         min_total_reads = 1000) {
  
  # Apply the same filtering criteria to get samples to keep
  filtered_metrics <- filter_samples_by_mock_content(
    metrics_df, 
    creek_filter = creek_filter,
    min_prop_mock = min_prop_mock,
    min_mock_species = min_mock_species,
    min_total_reads = min_total_reads
  )
  
  # Get the samplenames to keep
  samples_to_keep <- filtered_metrics$samplename
  
  # Filter the sample data
  filtered_data <- sample_df %>%
    filter(samplename %in% samples_to_keep)
  
  return(filtered_data)
}

# Usage examples:
filtered_TM_data <- filter_sample_data_by_metrics(
  sample_data, sample_metrics, creek_filter = "TM",
  min_prop_mock = 0.5, min_mock_species = 2, min_total_reads = 25000
)

filtered_PvCF_data <- filter_sample_data_by_metrics(
  sample_data, sample_metrics, creek_filter = "PvCF",
  min_prop_mock = 0.5, min_mock_species = 3, min_total_reads = 5000
)

filtered_wild_samples <- filter_sample_data_by_metrics(
  wild_sample_data, wild_sample_metrics, creek_filter = "PvScat",
  min_prop_mock = 0.5, min_mock_species = 3, min_total_reads = 5000
)

# Combine if desired
all_filtered_data <- rbind(
  filtered_TM_data,
  filtered_PvCF_data,
  filtered_wild_samples
)

# Check results
cat("Total filtered samples:", length(unique(all_filtered_data$samplename)), "\n")
print(summary(all_filtered_data))
```

now let's remove the low-quality samples from the dataframes to take forward into the model
```{r}
# Assuming you've already created these filtered_samples data frames:
# filtered_samples_TM, filtered_samples_PvCF, filtered_samples_PvScat

# Get all the high-quality samplenames from your filtered metrics
high_quality_samplenames <- unique(c(
  filtered_TM_data$samplename,
  filtered_PvCF_data$samplename,
  filtered_wild_samples$samplename
))

# Filter the original data frames to keep only high-quality samples
sample_data_HQ <- sample_data %>%
  filter(samplename %in% high_quality_samplenames)

wild_sample_data_HQ <- wild_sample_data %>%
  filter(samplename %in% high_quality_samplenames)

# Verify the filtering worked
cat("Original sample_data samples:", length(unique(sample_data$samplename)), "\n")
cat("High-quality sample_data samples:", length(unique(sample_data_HQ$samplename)), "\n")
cat("Samples removed from sample_data:", length(unique(sample_data$samplename)) - length(unique(sample_data_HQ$samplename)), "\n\n")

cat("Original wild_sample_data samples:", length(unique(wild_sample_data$samplename)), "\n")
cat("High-quality wild_sample_data samples:", length(unique(wild_sample_data_HQ$samplename)), "\n")
cat("Samples removed from wild_sample_data:", length(unique(wild_sample_data$samplename)) - length(unique(wild_sample_data_HQ$samplename)), "\n")

# Optional: View the first few rows of filtered data
print(head(sample_data_HQ))
print(head(wild_sample_data_HQ))
```

Okay we need to get all the sample_data together so we can make a station_mapping and 
```{r}
combined_sample_data <- rbind(sample_data_HQ,wild_sample_data_HQ)

#save for future use
saveRDS(combined_sample_data, here("intermediate-files","Prey18S_ALLObsSamples_data_20250824.RDS"))

```


We need to finalize some formatting and only pull species that are in the mock
```{r}
# First, let's check what species are in your combined data vs mock data
species_in_combined <- unique(combined_sample_data$species)
species_in_mock <- unique(combined_mock2$species)

# See which species are in both datasets
common_species <- intersect(species_in_combined, species_in_mock)
cat("Species common to both sample data and mock:", length(common_species), "\n")
print(common_species)

# See which species are only in samples (might need manual checking)
sample_only_species <- setdiff(species_in_combined, species_in_mock)
cat("Species only in sample data:", length(sample_only_species), "\n")
print(sample_only_species)

# See which species are only in mock
mock_only_species <- setdiff(species_in_mock, species_in_combined)
cat("Species only in mock data:", length(mock_only_species), "\n")
print(mock_only_species)

# Filter combined_sample_data to keep only species that are in the mock data
combined_sample_data_filtered <- combined_sample_data %>%
  filter(species %in% species_in_mock)

# Verify the filtering
cat("Original combined sample data rows:", nrow(combined_sample_data), "\n")
cat("Filtered combined sample data rows:", nrow(combined_sample_data_filtered), "\n")
cat("Species removed:", length(sample_only_species), "\n")

# Check the final structure
print(head(combined_sample_data_filtered))
cat("Unique species in final data:", length(unique(combined_sample_data_filtered$species)), "\n")

# Optional: If you want to also remove any species with very low total reads
# species_read_totals <- combined_sample_data_filtered %>%
#   group_by(species) %>%
#   summarise(total_reads = sum(Nreads), .groups = 'drop') %>%
#   arrange(total_reads)

# print("Species with lowest read counts:")
# print(head(species_read_totals))

# You might want to set a minimum read threshold
# min_read_threshold <- 100  # Adjust based on your needs
# species_to_keep <- species_read_totals %>%
#  filter(total_reads >= min_read_threshold) %>%
#   pull(species)

# combined_sample_data_final <- combined_sample_data_filtered %>%
#   filter(species %in% species_to_keep)

#cat("After removing low-abundance species:", nrow(combined_sample_data_final), "rows\n")
#cat("Species kept after abundance filtering:", length(species_to_keep), "\n")

#save for future use
saveRDS(combined_sample_data_filtered, here("intermediate-files","Prey18S_CF_TM_Wild_input_data.RDS"))

```



MODIFIED FROM ZG/EILY/OLE
```{r}

# Prepare for stan model 
input_metabarcoding_RDS <- combined_sample_data_filtered %>% dplyr::select(!samplename) %>% dplyr::rename(stationname = station)

input_mock_comm_RDS <- combined_mock2
#input_mock_comm_RDS <- input_mock_CFcomm_RDS
#input_mock_comm_RDS <- input_mock_RFcomm_RDS

```

create the station mapping dataframe that will be called by the formatting function
```{r}
# Create station mapping that handles different station naming conventions
create_station_mapping <- function(observation_data) {
  # First, get unique stations by creek
  station_mapping <- observation_data %>%
    distinct(creek, station) %>%
    arrange(creek, station) %>%
    group_by(creek) %>%
    mutate(
      # Create station index within each creek
      station_idx_within_creek = row_number(),
      station_type = case_when(
        creek == "PvCF" ~ "Diet",
        creek == "TM" ~ "TissueMix",
        creek == "PvScat" ~ "WildScat",
        TRUE ~ "Unknown"
      )
    ) %>%
    ungroup() %>%
    # Create a global station index
    mutate(station_idx = row_number()) %>%
    mutate(stationname = station) %>% 
    mutate(station = station_idx_within_creek) %>% 
    select(stationname, station, station_type)
  
  return(station_mapping)
}

# Usage:
station_mapping <- create_station_mapping(combined_sample_data_filtered)
print(station_mapping)

saveRDS(station_mapping, here("intermediate-files","Prey18S_observationData_stationMapping.RDS"))

```


Modified formatting function 3
```{r}
# Modified formatting function with external station mapping
format_metabarcoding_data <- function(input_metabarcoding_RDS, input_mock_comm_RDS, 
                                     station_mapping, reference_species = "Actinopteri") {
  require(tidyverse)
  
  Observation <- input_metabarcoding_RDS
  Mock <- input_mock_comm_RDS
  
  # Process Mock data FIRST - join station_idx before using it
  Mock <- Mock %>% 
    group_by(Community) %>% 
    mutate(station_idx = cur_group_id()) %>% 
    ungroup() %>%
    rename(Nreads = nReads) %>%
    mutate(
      time = 1,
      creek = 1,
      biol = 1,
      station = station_idx,
      stationname = Community
    ) %>% 
    replace(is.na(.), 0) %>% 
    filter(start_prop > 0 & Nreads > 0 & !is.na(Nreads)) %>% 
    unite(c(time, creek, station, biol, tech), col = "Sample", sep = ".", remove = FALSE)
  
  # Keep species present in both datasets
  keepSpecies <- intersect(Mock$species, Observation$species)
  Observation <- Observation %>% filter(species %in% keepSpecies)
  Mock <- Mock %>% filter(species %in% keepSpecies)
  
  # Create species index with reference species as the last index
  all_species <- unique(c(Mock$species, Observation$species))
  
  # Remove reference species from the main list
  main_species <- setdiff(all_species, reference_species)
  
  # Create ordered species list: main species first, reference species last
  ordered_species <- c(main_species, reference_species)
  
  # Create species index mapping
  sp_list <- data.frame(
    species = ordered_species,
    species_idx = 1:length(ordered_species),
    stringsAsFactors = FALSE
  )
  
  # Process Mock data with the new species index
  Mock <- Mock %>% 
    left_join(sp_list, by = "species") %>% 
    mutate(
      speciesname = species,
      species = species_idx
    ) %>% 
    group_by(station, tech, time, creek, biol) %>% 
    mutate(b_proportion = start_prop/sum(start_prop)) %>% 
    ungroup()
  
  # Process Observation data with the provided station mapping
  Observation <- Observation %>% 
    left_join(sp_list, by = "species") %>% 
    mutate(
      speciesname = species,
      species = species_idx
    ) %>% 
    left_join(station_mapping, by = "stationname") %>% 
    group_by(station, time, creek, biol) %>% 
    mutate(
      tech = match(tech, unique(tech)),
      tot_reads = sum(Nreads)
    ) %>% 
    filter(tot_reads > 0) %>% 
    ungroup() %>% 
    dplyr::select(-tot_reads)
  
  # Return final object
  list(
    Observation = Observation,
    Mock = Mock,
    N_pcr_mock = unique(input_mock_comm_RDS$N_pcr_mock),
    NSpecies = nrow(sp_list),
    station_list = station_mapping,
    sp_list = sp_list
  )
}
```


```{r}
qmdata <- format_metabarcoding_data(input_metabarcoding_RDS,input_mock_comm_RDS,
                          station_mapping = station_mapping,
                          reference_species = "Actinopteri")


obs <- qmdata

prop_check <- qmdata$Mock %>%
  group_by(station, tech) %>%
  summarise(
    sum_prop = sum(b_proportion),
    n_species = n(),
    .groups = 'drop'
  )

# Identify any problematic groups
prop_check %>% filter(abs(sum_prop - 1) > 0.001)

```
If no problems, continue to a sanity check

```{r}
p3 <- plot_proportion_comparison(qmdata$Mock,
                                 taxonomy_col = "speciesname",
                                 count_col = "Nreads",
                                 existing_prop_col = "propReads",
                                 group_cols = c("Community", "tech"),
                                 top_n_taxa = 10,
                                 plot_title = "Count vs Clac Proportions")
print(p3)
```
okay working as expected after transform


Modified model running script to handle changes that are leading to crazy issues like not setting the reference species to an appropriate one
```{r}
library(rstan)
library(MCMCpack) #for rdirichelet function
library(gridExtra)
library(unikn)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())


N_pcr_cycles <- 39
MOCK <- qmdata$Mock  

```

Modified ALR transform for model input formatting
```{r}

##### FIXED VERSION WITH spread() ####
alrTransform <- function(MOCK){
  require(tidyverse)
  require(compositions)
  
  p_mock <- MOCK %>% 
    dplyr::select(species, station, tech, b_proportion) %>% 
    rename(tech_rep = tech) %>% 
    spread(key = species, value = b_proportion, fill = 1e-9) %>%  # Use spread() instead
    ungroup() 
  
  colnames(p_mock)[3:(length(unique(MOCK$species))+2)] <- paste0("alr_", 1:length(unique(MOCK$species)))
  
  p_mock <- alr(p_mock[,3:ncol(p_mock)]) %>% as.matrix() %>% as.data.frame()
  p_mock[,length(unique(MOCK$species))] <- 0  #add reference zero expressly
  names(p_mock)[length(unique(MOCK$species))] <- paste0("alr_", length(unique(MOCK$species)))
  
  p_mock <-  cbind(MOCK %>% dplyr::select(tech, station) %>% distinct(),
                   p_mock) %>% ungroup()
  names(p_mock)[1] <- "tech_rep"
  
  return(p_mock)
}

```
We are going to split up the functions because as written in one giant script is making troubleshooting hard, later we can make them all into one Functions.R but for now let's keep them separate

makeDesign function to create the input for the stan model running
```{r}
makeDesign <- function(obs, #obs is a named list with elements Observation, Mock, N_pcr_mock, sp_list
                       N_pcr_cycles){ #N_pcr_cycles is the number of PCR cycles in your experimental/enviro samples; currently a single value, could be made into a vector if this number varies
  #library(tidyverse)
  library(MCMCpack)
  library(compositions)
  library(rstan)
  library(dplyr)
  
  
  mock <- obs$Mock
  observed <- obs$Observation
  
  p_mock_all <- alrTransform(mock)
  
  mock_3 <- mock %>% 
  dplyr::select(species, station, tech, Nreads) %>% 
  ungroup() %>% 
  mutate(species = paste0("sp_", species)) %>% 
  pivot_wider(names_from = species, values_from = Nreads, 
              values_fill = 0)  # FIXED: named list

  N_pcr_mock <- rep(obs$N_pcr_mock, nrow(p_mock_all)) #assumes all have the same Npcr
  
  
  p_samp_all <- observed %>% 
    ungroup() %>% 
    unite(time, creek, station, biol, col = "station") %>% 
    dplyr::select(station, tech, species, Nreads) %>% 
    rename(tech_rep = tech) %>% 
    mutate(species = paste0("sp_", species)) %>% 
    arrange(species) %>% 
    group_by(station, tech_rep,species) %>% 
    dplyr::summarise(Nreads= sum(Nreads)) %>% 
    ungroup() %>% 
   pivot_wider(names_from = species, values_from = Nreads, 
              values_fill = 0)
  N_pcr_samp <- rep(N_pcr_cycles, nrow(p_samp_all))
  
  ########################################################################
  #### Create data frames that can be read into Stan model
  ########################################################################
  
  NOM <- as.name(colnames(p_mock_all)[1])
  formula_a <- eval(NOM) ~ N_pcr_mock -1
  model_frame <- model.frame(formula_a, p_mock_all)
  model_vector_a_mock <- model.matrix(formula_a, model_frame) %>% as.numeric()
  N_pcr_mock_small <- cbind(N_pcr_mock, p_mock_all) %>%  filter(tech_rep == 1) %>% pull(N_pcr_mock)
  formula_b <- eval(NOM) ~ N_pcr_mock_small -1
  model_frame <- model.frame(formula_b, p_mock_all%>% filter(tech_rep==1))
  model_vector_a_mock_small <- model.matrix(formula_b, model_frame) %>% as.numeric()
  
  N_obs_mock       <- nrow(p_mock_all)
  
  # unknown communities second
  # species compositions (betas)
  
  NOM <- as.name(colnames(p_samp_all)[1])    
  
  p_samp_all$station <- as.factor(p_samp_all$station)
  N_station = length(unique(p_samp_all$station))
  p_samp_all$tech_rep <- as.factor(p_samp_all$tech_rep)
  if(N_station == 1){
    formula_b <- eval(NOM) ~ 1  
  } else {
    formula_b <- eval(NOM) ~ station
  }
  
  model_frame <- model.frame(formula_b, p_samp_all)
  model_matrix_b_samp <- model.matrix(formula_b, model_frame)
  
  # choose a single representative for each station to make predictions to
  model_frame <- model.frame(formula_b, p_samp_all %>% filter(tech_rep==1))
  model_matrix_b_samp_small <- model.matrix(formula_b, model_frame)
  
  # efficiencies (alpha)
  formula_a <- eval(NOM) ~ N_pcr_samp -1
  model_frame <- model.frame(formula_a, p_samp_all)
  model_vector_a_samp <- model.matrix(formula_a, model_frame) %>% as.numeric()
  N_pcr_samp_small <- cbind(N_pcr_samp, p_samp_all) %>% filter(tech_rep == 1) %>% pull(N_pcr_samp)
  formula_b <- eval(NOM) ~ N_pcr_samp_small -1
  
  model_frame <- model.frame(formula_b, p_samp_all %>% filter(tech_rep==1))
  model_vector_a_samp_small <- model.matrix(formula_b, model_frame) %>% as.numeric()
  
  #counters 
  N_obs_samp_small <- nrow(model_matrix_b_samp_small)
  N_obs_samp <- nrow(p_samp_all)
  N_b_samp_col <- ncol(model_matrix_b_samp)
  
  
  #### Make Stan objects
  
  stan_data <- list(
    N_species = ncol(p_samp_all)-2,   # Number of species in data
    N_obs_samp = nrow(p_samp_all), # Number of observed community samples and tech replicates ; this will be Ncreek * Nt * Nbiol * Ntech * 2 [for upstream/downstream observations]
    N_obs_mock = nrow(p_mock_all), # Number of observed mock samples, including tech replicates
    N_obs_samp_small = nrow(p_samp_all %>% filter(tech_rep == 1)), # Number of unique observed community samples ; this will be Ncreek * Nt * Nbiol * 2 [for upstream/downstream observations]
    
    # Observed data of community matrices
    sample_data = p_samp_all %>% dplyr::select(contains("sp")),
    sample_vector = unique(p_samp_all$station),
    mock_data   = mock_3 %>% dplyr::select(contains("sp")),
    sp_list = obs$sp_list,
    
    # True proportions for mock community
    #mock_true_prop = p_mock_all %>% dplyr::select(contains("sp")),
    alr_mock_true_prop = p_mock_all %>% dplyr::select(contains("alr")),
    
    # vectors of PCR numbers
    N_pcr_samp = N_pcr_samp,
    N_pcr_mock = N_pcr_mock,
    
    # Design matrices: field samples
    N_b_samp_col = N_b_samp_col,
    model_matrix_b_samp = model_matrix_b_samp,
    model_matrix_b_samp_small = as.array(model_matrix_b_samp_small),
    model_vector_a_samp = model_vector_a_samp,
    model_vector_a_samp_small = as.array(model_vector_a_samp_small),
    
    # Design matrices: mock community samples
    model_vector_a_mock = as.array(model_vector_a_mock),
    
    # Priors
    alpha_prior = c(0,0.5),  # normal prior
    beta_prior = c(0,5),    # normal prior
    tau_prior = c(1,2)   # gamma prior
  )
  
  return(stan_data)
  
}

```

Running the nested functions
```{r}
stan_metabarcoding_data <- makeDesign(qmdata, N_pcr_cycles = 39)
stan_metabarcoding_data$alr_mock_true_prop
stan_metabarcoding_data$mock_data
stan_metabarcoding_data$sample_vector

```




okay now we can move forward with the next steps in the stan model and QM model

No changes from original:
```{r}

QM_likelihood <- function(stanmodelname, stan_metabarcoding_data){
  M <- stan_model(stanmodelname)
  
  stanOpt <- optimizing(M, data=stan_metabarcoding_data, iter=30000,draws=0,
                        verbose=T,  
                        tol_param=1e-40,
                        algorithm="LBFGS",
                        hessian = TRUE)
  
  MLest <- stanOpt$par[grep("int_samp_small", names(stanOpt$par))] %>%
    matrix(ncol = stan_metabarcoding_data$N_species) %>% 
    as.data.frame()
  names(MLest) <- stan_metabarcoding_data$sp_list$species
  rownames(MLest) <- stan_metabarcoding_data$sample_vector
  ML_a <- stanOpt$par[grep("alpha\\[", names(stanOpt$par))]  
  ML_a <- data.frame("alpha_est" = ML_a, 
                     "species" = stan_metabarcoding_data$sp_list$species)
  
  
  return(list(
    ML_modelfit = stanOpt,
    ML_estimates = MLest,
    ML_alpha_est = ML_a
  ))
  
}

ML_out <- QM_likelihood(here("scripts","models","quant_metabar_rosetta_noSampleEta.stan"), stan_metabarcoding_data)

write_rds(ML_out, here("intermediate-files","Test5_NoTMMock_20250822_ML_out.RDS"))

```

a) Maximum Likelihood (ML) Estimation: QM_likelihood function
What it does: This function performs optimization. It finds the single set of parameter values (e.g., alpha, beta, tau) that maximize the probability (likelihood) of observing your data (the mock and field sample read counts). It's a point estimate, giving you one "best guess" for the corrected proportions.

The Process:

  1. stan_model(): Compiles the Stan code.

  2. optimizing(): Runs an optimization algorithm (LBFGS) to find the parameter values that maximize the log-likelihood. It does not run a full Bayesian sampling.

  3. The function then extracts the parameters related to int_samp_small, which are the model's estimates of the true proportions for your field samples (stan_metabarcoding_data$sample_vector).

Pros: Very fast.

Cons: Provides no measure of uncertainty (no confidence intervals). If the model has multiple potential solutions, it will only find one.


Let's plot theoutputs to check the single estimate fit and output props before we run the full model.
```{r}
library(tidyverse)

# Check sampletype values first
sample_types <- ML_out$ML_estimates %>%
  rownames_to_column("sample") %>%
  separate(col = sample, into = c("time", "sampletype", "station_num", "biol"), sep = "_") %>%
  pull(sampletype) %>%
  unique()
print(sample_types)  # Verify if "PvcF" or "PvCF" exists

# Proceed with corrected filter
plot_data_CF <- ML_out$ML_estimates %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "species", values_to = "proportion") %>%
  separate(col = sample, into = c("time", "sampletype", "station_num", "biol"), 
           remove = FALSE, sep = "_") %>% 
  mutate(station_num = as.numeric(station_num)) %>%
  left_join(station_mapping, by = c("station_num" = "station")) %>%
  filter(proportion > 0.001) %>%
  filter(sampletype == "PvCF")  # Adjusted to match actual case

# Check if plot_data has rows
if (nrow(plot_data_CF) == 0) {
  stop("No data left after filtering! Check sampletype/stations.")
}


plot_data_TM <- ML_out$ML_estimates %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "species", values_to = "proportion") %>%
  separate(col = sample, into = c("time", "sampletype", "station_num", "biol"), 
           remove = FALSE, sep = "_") %>% 
  mutate(station_num = as.numeric(station_num)) %>%
  left_join(station_mapping, by = c("station_num" = "station")) %>%
  filter(proportion > 0.001) %>%
  filter(sampletype == "TM")  # Adjusted to match actual case

# Check if plot_data has rows
if (nrow(plot_data_TM) == 0) {
  stop("No data left after filtering! Check sampletype/stations.")
}


# Plot
ggplot(plot_data_CF, aes(x = biol, fill = species, y = proportion)) +
  geom_col(position = "stack", width = 0.8) +
  labs(x = "Biological Replicate", y = "Proportion in sample", fill = "Species") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
    legend.position = "bottom"
  ) +
  facet_grid(sampletype ~ stationname + time, scales = "free_x", space = "free") +
  guides(fill = guide_legend(ncol = 3))



ggsave(here("Figures","20250821_ctrlfeeding_proportions_after_qm_ML.png"), width = 18, height = 10, units = "cm")


# Plot
ggplot(plot_data_TM, aes(x = biol, fill = species, y = proportion)) +
  geom_col(position = "stack", width = 0.8) +
  labs(x = "Biological Replicate", y = "Proportion in sample", fill = "Species") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
    legend.position = "bottom"
  ) +
  facet_grid(sampletype ~ stationname + time, scales = "free_x", space = "free") +
  guides(fill = guide_legend(ncol = 3))

ggsave(here("Figures","20250821_TM_proportions_after_qm_ML.png"), width = 18, height = 10, units = "cm")


```

2) What the Image Outputs Are Actually Representing
The image is a stacked barplot of the Maximum Likelihood estimates (ML_estimates) for samples where sampletype == "PvCF".

The Values (Y-axis): These are not raw read counts. They are the model-corrected, estimated true proportions of each species in the diet sample. The model has used the information from the mock communities to "undo" the PCR and sequencing biases. For example, if Crangon amplifies twice as efficiently as Nereididae, and you see a 50/50 read split, the model will estimate that the true proportion was actually ~33% Crangon and ~66% Nereididae.

The Bars: Each bar represents one biological replicate (e.g., 1_PvCF_1_1, 1_PvCF_1_2, etc.). The entire bar sums to 1 (or 100%).

Why it might look wrong:

The correction can be extreme. If a species has a very high alpha (amplifies very well), its read proportion will be scaled down dramatically. Conversely, a species with a low alpha will have its proportion scaled up. Your bayes_out$Bayes_alpha_est shows these correction factors. For instance, Neotrypaea has a positive alpha (+0.11), meaning it amplifies better than the reference species (Actinopteri, whose alpha is fixed at 0). Its read counts will therefore be downwardly adjusted in the final proportion estimate.


Okay, well there is a lot of noise, and it is hard to visualise the ML_estimates due to it being one option rather than the full model. But if it looks extremely crazy there is likely something wrong with the model fit. Solutions could be: to clean up the data more, or split the TissueMixtures from the Controlled feeding study to run separately, or add more samples so there is more diversity

```{r}
# Plot
ggplot(plot_data_TM, aes(x = biol, fill = species, y = proportion)) +
  geom_col(position = "stack", width = 0.8) +
  labs(x = "Biological Replicate", y = "Proportion in sample", fill = "Species") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
    legend.position = "bottom"
  ) +
  facet_grid(sampletype ~ stationname + time, scales = "free_x", space = "free") +
  guides(fill = guide_legend(ncol = 3))

```
After including all the species and having both the CF and TM samples in there, it looks like the model is really not working to handle the zeros as it should, mammal and spiny dogfish are wildly over represented... But these estimates are prelim, so let's actually let the model run to see what the real output is.

If need be we can remove the mussel polychaete worm and crangon/spiny dogfish if they are still being overestimated.

Need to sort out how to add in the alpha's from TM for Paneaus and mussel polychaete worm since I don't think they made it into the mocks well.

Okay I think the TM for the lamprey and the paneaus are breaking things... need to figure out a better way to deal with that and we need to take them out. 

Some checks:
```{r}
# Check species lists
cat("Mock species:", unique(qmdata$Mock$species), "\n")
cat("Observation species:", unique(qmdata$Observation$species), "\n")

# Check dimensions
cat("Mock data dimensions:", dim(stan_metabarcoding_data$mock_data), "\n")
cat("Sample data dimensions:", dim(stan_metabarcoding_data$sample_data), "\n")

# Check ALR proportions
print("First few rows of ALR transformed mock proportions:")
print(head(stan_metabarcoding_data$alr_mock_true_prop))

# Check design matrices
print("Design matrix for samples:")
print(head(stan_metabarcoding_data$model_matrix_b_samp))
print("PCR cycles vector:")
print(head(stan_metabarcoding_data$model_vector_a_samp))
```


```{r}
QM_bayes <- function(stanmodelname, stan_metabarcoding_data, NCHAINS = 4, WARMUP = 1000, ITER = 4000){
  require(tidyverse)
  require(rstan)
  rstan_options(auto_write = TRUE)
  options(mc.cores = parallel::detectCores())
  
  
  stan_pars <- c( 
    "alpha",
    "beta",
    "eta_mock",
    "tau",
    "mu_samp",
    "mu_mock",
    "int_samp_small"
  )
  
    stanMod = stan(file = stanmodelname ,data = stan_metabarcoding_data,
                   verbose = FALSE, chains = NCHAINS, thin = 1,
                   warmup = WARMUP, iter = ITER,
                   control = list(adapt_init_buffer = 175,
                                  max_treedepth=16,
                                  stepsize=0.01,
                                  adapt_delta=0.7,
                                  metric="diag_e"),
                   pars = stan_pars,
                   refresh = 10,
                   boost_lib = NULL 
    )  
    
    
    mean_est <- summary(stanMod, par = "int_samp_small")$summary[,1] %>%
      matrix(ncol = stan_metabarcoding_data$N_species, byrow = TRUE) %>% 
      as.data.frame()
      names(mean_est) <- stan_metabarcoding_data$sp_list$species
      rownames(mean_est) <- stan_metabarcoding_data$sample_vector
    ci25_est <- summary(stanMod, par = "int_samp_small")$summary[,5] %>%
      matrix(ncol = stan_metabarcoding_data$N_species, byrow = TRUE) %>% 
      as.data.frame()
      names(ci25_est) <- stan_metabarcoding_data$sp_list$species
      rownames(ci25_est) <- stan_metabarcoding_data$sample_vector
    
    ci75_est <- summary(stanMod, par = "int_samp_small")$summary[,7] %>%
      matrix(ncol = stan_metabarcoding_data$N_species, byrow = TRUE) %>% 
      as.data.frame()
      names(ci75_est) <- stan_metabarcoding_data$sp_list$species
      rownames(ci75_est) <- stan_metabarcoding_data$sample_vector
    
    mean_a_est <- summary(stanMod, par = "alpha")$summary[,1]
    mean_a_est <- data.frame("alpha_est" = mean_a_est, 
                       "species" = stan_metabarcoding_data$sp_list$species)
    
    #unique(meta.samples$sample)
    
    return(list(
      Bayes_modelfit = stanMod,
      Bayes_estimates = mean_est,
      Bayes_25ci = ci25_est,
      Bayes_75ci = ci75_est,
      Bayes_alpha_est = mean_a_est
    ))
    
  }
```

b) Full Bayesian Estimation: QM_bayes function
What it does: This function performs Markov Chain Monte Carlo (MCMC) sampling. Instead of finding one best value, it draws thousands of samples from the posterior distribution of the parameters. This distribution represents the model's belief about the true values, considering both the data and the prior beliefs. Your bayes_out object contains the results of this sampling.

The Process:

  1. stan(): Runs the MCMC sampler (NUTS algorithm) for multiple chains.

  2. For each parameter, it generates a distribution of values. The summary() function then calculates summary        statistics for these distributions (e.g., mean, sd, 2.5%, 97.5%).

  3. The function extracts the mean of the posterior distribution for int_samp_small (Bayes_estimates), as well        as the 2.5th and 75th percentiles (a credible interval) for these proportions.

- Pros: Provides a full picture of uncertainty (credible intervals). More robust to complex model geometries.

- Cons: Computationally expensive (slow).

In summary: You run the model twice. First, quickly, to get a point estimate (ML_out). Second, thoroughly, to get a mean estimate with uncertainty (bayes_out). For final analysis, use the Bayesian output (bayes_out) as it is far more informative.

```{r}
####################################################################
# Run Bayesian QM model
####################################################################

bayes_out <- QM_bayes(here("scripts","models","quant_metabar_rosetta_noSampleEta.stan"), stan_metabarcoding_data)

saveRDS(bayes_out, here("intermediate-files","20250824_bayesout_ControlFeedingTMWildScats.RDS"))

summaryout <- summary(bayes_out$Bayes_modelfit)$summary
write.csv(summaryout, here("intermediate-files","20250824_bayesout_ControlFeedingTMWildScats_summary.csv"))

bayes_out <- readRDS( here("intermediate-files","20250824_bayesout_ControlFeedingTMWildScats.RDS"))

bayes_out$Bayes_alpha_est
bayes_out$Bayes_estimates %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "species") -> tibble_bayes

bayes_out$Bayes_25ci %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "species") -> tibble_bayes_25

bayes_out$Bayes_75ci %>%
  rownames_to_column("sample") %>%
  pivot_longer(-sample, names_to = "species") -> tibble_bayes_75

tibble_bayes$Bayes_25ci <- tibble_bayes_25$value
tibble_bayes$Bayes_75ci <- tibble_bayes_75$value

bayes_out$Bayes_modelfit

```

The model is struggling. The very low n_eff and high Rhat values for a few species in your bayes_out printout are major red flags. Suggests that species 1,5, and 9 may be causing issues (Nereididae,Rajidae, and Cephalopoda respectively) This indicates the MCMC chains did not converge properly. The results cannot be trusted if convergence is bad, so we need to modify the inputs and be more conservative with species. This is likely due to a mismatch between model and data, too vague priors, or an overly complex model for the data at hand, we need more data so we should bring in wild samples, but we definitely need to 

```{r}
# 4. Run the model with the COMBINED mock data and the NEW station_mapping
combined_model_result <- run_QM_model(
  input_metabarcoding_RDS = input_metabarcoding_RDS,
  input_mock_comm_RDS = combined_mock, # Use the combined mock
  N_pcr_cycles = 39,
  station_mapping = combined_station_mapping, # Use the NEW mapping for mocks
  reference_species = "Actinopteri",
  stanmodel = "quant_metabar_rosetta_noSampleEta.stan",
  method = "Bayes") # or "ML"

```


```{r}
library(stringr) # We'll use this to extract the station number from the sample name

# 1. Extract the parameter and convert to a data frame
pars2 <- rstan::extract(bayes_out$Bayes_modelfit, par = "int_samp_small")

# 2. Create a mapping tibble for samples - FIXED REGEX
sample_mapping <- tibble(
  station_idx = 1:length(stan_metabarcoding_data$sample_vector),
  sample_name = stan_metabarcoding_data$sample_vector
) %>%
  # Separate the sample name into its components
  separate(sample_name, into = c("time", "sampletype", "station_num", "biol"), 
           remove = FALSE, sep = "_") %>%
  # Convert station_num to numeric
  mutate(station_num = as.numeric(station_num)) %>%
  # Join with your station_mapping
  left_join(station_mapping, by = c("station_num" = "station")) %>%
  # Optional: recreate the original sample_name if needed
  mutate(sample_name = paste(time, sampletype, station_num, biol, sep = "_"))

# 3. Create a mapping tibble for species
species_mapping <- tibble(
  species_idx = 1:nrow(stan_metabarcoding_data$sp_list),
  species_name = stan_metabarcoding_data$sp_list$species
)

# 4. Process the extracted samples
int_samp_small_tibble <- as_tibble(pars2$int_samp_small) %>%
  mutate(draw = 1:n()) %>% 
  pivot_longer(
    cols = -draw,
    names_to = "param_name",
    values_to = "proportion"
  ) %>%
  separate(param_name, into = c("station_idx", "species_idx"), sep = "\\.", convert = TRUE) %>%
  # Convert station_idx to numeric to match with sample_mapping
  mutate(station_idx = as.numeric(station_idx)) %>%
  # Join with our enhanced mapping table
  left_join(sample_mapping, by = "station_idx") %>%
  left_join(species_mapping, by = "species_idx")

# 5. Check the results - should now show different station numbers
print(sample_mapping, n = 20)
tail(sample_mapping)

# Check the final tibble
glimpse(int_samp_small_tibble)
# You can see the structure now includes both the full sample name and the station name
head(int_samp_small_tibble)

saveRDS(int_samp_small_tibble, here("intermediate-files","CorrectionBiasRun","20250824_bayesout_ControlFeedingTMWildScats_int_samp_small_tibble.RDS"))

```

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)

summarize_bayes_output <- function(bayes_out, stan_data, station_mapping) {
  # Function to summarize Bayesian output with flexible station mapping
  
  # 1. Extract the mean estimates (matching your original code)
  mean_est <- summary(bayes_out$Bayes_modelfit, par = "int_samp_small")$summary[,1] %>%
    matrix(ncol = stan_data$N_species, byrow = TRUE) %>% 
    as.data.frame()
  
  names(mean_est) <- stan_data$sp_list$species
  rownames(mean_est) <- stan_data$sample_vector
  
  # Convert to tibble for easier manipulation
  mean_est_tibble <- mean_est %>%
    rownames_to_column("sample") %>%
    pivot_longer(-sample, names_to = "species", values_to = "mean_proportion")
  
  # 2. Create the full posterior tibble (for uncertainty analysis)
  pars <- rstan::extract(bayes_out$Bayes_modelfit, par = "int_samp_small")
  
  posterior_tibble <- as_tibble(pars$int_samp_small) %>%
    mutate(draw = 1:n()) %>% 
    pivot_longer(
      cols = -draw,
      names_to = "param_name",
      values_to = "proportion"
    ) %>%
    separate(param_name, into = c("station_idx", "species_idx"), sep = "\\.", convert = TRUE) %>%
    mutate(station_idx = as.numeric(station_idx),
           species_idx = as.numeric(species_idx))
  
  # Create mapping for samples
  sample_mapping <- tibble(
    station_idx = 1:length(stan_data$sample_vector),
    sample_name = stan_data$sample_vector
  ) %>%
    # Extract components from sample name - flexible approach
    separate(sample_name, into = c("time", "sampletype", "station_num", "biol"), 
             remove = FALSE, sep = "_", fill = "right") %>%
    mutate(station_num = as.numeric(station_num)) %>%
    left_join(station_mapping, by = c("station_num" = "station"))
  
  # Create mapping for species
  species_mapping <- tibble(
    species_idx = 1:nrow(stan_data$sp_list),
    species_name = stan_data$sp_list$species
  )
  
  # Join everything together - FIXED: select only after joins are complete
  full_posterior <- posterior_tibble %>%
    left_join(sample_mapping, by = "station_idx") %>%
    left_join(species_mapping, by = "species_idx")
  
  
  # 3. Create summary statistics for each sample-species combination
  summary_stats <- full_posterior %>%
    group_by(sample_name, time, sampletype, station_num, stationname, biol, species_name) %>%
    summarise(
      mean_prop = mean(proportion),
      median_prop = median(proportion),
      lower_95 = quantile(proportion, 0.025),
      upper_95 = quantile(proportion, 0.975),
      sd_prop = sd(proportion),
      .groups = 'drop'
    )
  
  # 4. Create species-level summaries
  species_summary <- full_posterior %>%
    group_by(species_name) %>%
    summarise(
      max_proportion = max(proportion),
      mean_proportion = mean(proportion),
      .groups = 'drop'
    )
  
  # 5. Prepare data for plotting
  plotting_data <- summary_stats %>%
    # Add any additional processing you need here
    separate(time, into = c("month", "year"), sep = 2, remove = FALSE) %>%
    unite(newtime, c(year, month), sep = "-", remove = FALSE)
  
  # Return all the useful data frames in a list
  return(list(
    mean_estimates = mean_est_tibble,
    full_posterior = full_posterior,
    summary_stats = summary_stats,
    species_summary = species_summary,
    plotting_data = plotting_data
  ))
}

```

```{r}
# Usage example:
summary_bayes_out <- summarize_bayes_output(bayes_out, stan_metabarcoding_data, station_mapping)

# Access the different components:
mean_estimates <- summary_bayes_out$mean_estimates
full_posterior <- summary_bayes_out$full_posterior
summary_stats <- summary_bayes_out$summary_stats
species_summary <- summary_bayes_out$species_summary
plotting_data <- summary_bayes_out$plotting_data

# Save the plotting data as in your example
saveRDS(plotting_data, here("intermediate-files","CorrectionBiasRun", "20250824_bayesout_ControlFeedingTMWildScats_qm_data_plotting.rds"))

# Check the results
glimpse(plotting_data)
head(species_summary)

```


```{r}
# Save the other summary results
saveRDS(mean_estimates, here("intermediate-files","CorrectionBiasRun", "20250824_bayesout_ControlFeedingTMWildScats_qm_mean_estimates.rds"))
saveRDS(summary_stats, here("intermediate-files","CorrectionBiasRun", "20250824_bayesout_ControlFeedingTMWildScats_qm_samp_small_summary_stats.rds"))
saveRDS(species_summary, here("intermediate-files","CorrectionBiasRun", "20250824_bayesout_ControlFeedingTMWildScats_qm_species_summary.rds"))
saveRDS(full_posterior, here("intermediate-files","CorrectionBiasRun", "20250824_bayesout_ControlFeedingTMWildScats_full_posterior.rds"))

# Quick visualization
ggplot(summary_stats, aes(x = species, y = mean_prop, color = stationname)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), 
                position = position_dodge(width = 0.5), width = 0.2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Posterior estimates of species proportions by station",
       x = "Species", y = "Estimated proportion")
```

Modified plotting functions to make it more streamline across runs and models
```{r, plotting functions post model fitting and running}
library(ggridges)
library(lubridate)

# 1. Fixed ridgeline plot function (handles numeric time values)
plot_bayes_ridges <- function(posterior_data, 
                              target_sampletype = NULL, 
                              target_station = NULL,
                              min_proportion = 0.001,
                              time_as_factor = TRUE) {
  # Prepare data - your tibble already has the separated components
  plot_data <- posterior_data %>%
    filter(proportion > min_proportion)
  
  # Convert time to appropriate format (numeric or factor)
  if (time_as_factor) {
    plot_data <- plot_data %>% mutate(time = factor(time))
  } else {
    plot_data <- plot_data %>% mutate(time = as.numeric(time))
  }
  
  # Apply filters if specified
  if (!is.null(target_sampletype)) {
    plot_data <- plot_data %>% filter(sampletype %in% target_sampletype)
  }
  if (!is.null(target_station)) {
    plot_data <- plot_data %>% filter(stationname %in% target_station)
  }
  
  # Check if we have data after filtering
  if (nrow(plot_data) == 0) {
    warning("No data remaining after filtering. Check your target_sampletype and target_station parameters.")
    return(ggplot() + geom_blank() + labs(title = "No data available after filtering"))
  }
  
  # Create the plot
  p <- plot_data %>%
    ggplot(aes(x = proportion, y = time, fill = time)) + 
    geom_density_ridges(rel_min_height = 0.01) +
    labs(x = "Proportion of DNA after QM correction", 
         y = "Time Point", 
         fill = "Time Point",
         title = paste("Posterior Distributions:", 
                       ifelse(!is.null(target_sampletype), paste("Sample type:", target_sampletype), ""),
                       ifelse(!is.null(target_station), paste("Station:", target_station), ""))) +
    theme_bw() +
    facet_wrap(~species_name, scales = "free_x")
  
  return(p)
}

# 2. Flexible bar plot function (for summary data)
plot_bayes_bars <- function(summary_data,
                            target_stations = NULL, 
                            target_sampletypes = NULL,
                            min_proportion = 0.001) {
  
  # Prepare data - assuming summary_data has mean_prop, species_name, station_name, etc.
  plot_data <- summary_data %>%
    filter(mean_prop > min_proportion)
  
  # Apply filters if specified
  if (!is.null(target_stations)) {
    plot_data <- plot_data %>% filter(stationname %in% target_stations)
  }
  if (!is.null(target_sampletypes)) {
    plot_data <- plot_data %>% filter(sampletype %in% target_sampletypes)
  }
  
  # Create the plot
  p <- plot_data %>%
    ggplot(aes(x = stationname, fill = species_name, y = mean_prop)) +
    geom_col(position = "stack") +
    labs(x = "Station", 
         y = "Mean Proportion of DNA after QM correction", 
         fill = "Species") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Add faceting if you want to separate by sampletype or time
  if ("sampletype" %in% names(plot_data) && length(unique(plot_data$sampletype)) > 1) {
    p <- p + facet_wrap(~sampletype, scales = "free_x")
  }
  
  return(p)
}

# Also need to fix the timeseries function since it has the same issue:
plot_bayes_timeseries <- function(posterior_data,
                                  target_station = NULL,
                                  target_species = NULL,
                                  min_proportion = 0.001,
                                  highlight_period = NULL,
                                  time_as_numeric = TRUE) {
  
  # Prepare data
  plot_data <- posterior_data %>%
    filter(proportion > min_proportion)
  
  # Convert time to appropriate format
  if (time_as_numeric) {
    plot_data <- plot_data %>% mutate(time_num = as.numeric(time))
  } else {
    plot_data <- plot_data %>% mutate(time_num = factor(time))
  }
  
  # Apply filters if specified
  if (!is.null(target_station)) {
    plot_data <- plot_data %>% filter(station_name %in% target_station)
  }
  if (!is.null(target_species)) {
    plot_data <- plot_data %>% filter(species_name %in% target_species)
  }
  
  # Calculate summary statistics for plotting
  summary_data <- plot_data %>%
    group_by(time_num, station_name, species_name, sampletype) %>%
    summarise(
      mean_prop = mean(proportion),
      median_prop = median(proportion),
      lower_95 = quantile(proportion, 0.025),
      upper_95 = quantile(proportion, 0.975),
      .groups = 'drop'
    )
  
  # Create the plot
  p <- summary_data %>%
    ggplot(aes(x = time_num, y = mean_prop, color = species_name)) +
    geom_point() +
    geom_errorbar(aes(ymin = lower_95, ymax = upper_95), alpha = 0.5) +
    labs(x = "Time Point", 
         y = "Proportion of DNA after QM correction", 
         color = "Species") +
    theme_bw()
  
  # Facet by species if multiple species are shown
  if (length(unique(summary_data$species_name)) > 1) {
    p <- p + facet_wrap(~species_name, scales = "free_y")
  }
  
  # Add highlight period if specified (only works if time is numeric)
  if (!is.null(highlight_period) && time_as_numeric) {
    p <- p + 
      annotate("rect", 
               xmin = highlight_period$start, 
               xmax = highlight_period$end, 
               ymin = 0, ymax = Inf, 
               alpha = 0.2, fill = "darkred")
  }
  
  return(p)
}

# 4. Sample composition plot by sampletype and station
plot_sample_composition <- function(posterior_data, 
                                   target_sampletypes = NULL,
                                   target_stations = NULL,
                                   min_proportion = 0.01,
                                   facet_by_station = TRUE,
                                   show_biol_reps = TRUE) {
  
  # Calculate mean proportions for each sample-species combination
  summary_data <- posterior_data %>%
    group_by(sample_name, time, sampletype, stationname, biol, species_name) %>%
    summarise(mean_prop = mean(proportion), .groups = 'drop') %>%
    filter(mean_prop > min_proportion)
  
  # Apply filters if specified
  if (!is.null(target_sampletypes)) {
    summary_data <- summary_data %>% filter(sampletype %in% target_sampletypes)
  }
  if (!is.null(target_stations)) {
    summary_data <- summary_data %>% filter(stationname %in% target_stations)
  }
  
  # Create a better x-axis label that shows biological replicates clearly
  if (show_biol_reps) {
    summary_data <- summary_data %>%
      mutate(sample_label = paste("BioRep", biol))
  } else {
    summary_data <- summary_data %>%
      mutate(sample_label = sample_name)
  }
  
  # Create the plot
  p <- summary_data %>%
    ggplot(aes(x = sample_label, fill = species_name, y = mean_prop)) +
    geom_col(position = "stack") +
    labs(x = "Biological Replicate", 
         y = "Mean Proportion", 
         fill = "Species",
         title = paste("Sample Composition:",
                       ifelse(!is.null(target_sampletypes), 
                              paste("Type:", paste(target_sampletypes, collapse = ", ")), ""),
                       ifelse(!is.null(target_stations),
                              paste("Stations:", paste(target_stations, collapse = ", ")), ""))) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Add faceting by station if requested
  if (facet_by_station && "station_name" %in% names(summary_data)) {
    p <- p + facet_wrap(~station_name, scales = "free_x")
  }
  
  # Alternatively, facet by sampletype if not faceting by station
  else if (!facet_by_station && "sampletype" %in% names(summary_data)) {
    p <- p + facet_wrap(~sampletype, scales = "free_x")
  }
  
  return(p)
}

# 5. Enhanced version with both sampletype and station faceting
plot_sample_composition_grid <- function(posterior_data, 
                                        target_sampletypes = NULL,
                                        target_stations = NULL,
                                        min_proportion = 0.01) {
  
  # Calculate mean proportions
  summary_data <- posterior_data %>%
    group_by(sample_name, time, sampletype, stationname, biol, species_name) %>%
    summarise(mean_prop = mean(proportion), .groups = 'drop') %>%
    filter(mean_prop > min_proportion)
  
  # Apply filters
  if (!is.null(target_sampletypes)) {
    summary_data <- summary_data %>% filter(sampletype %in% target_sampletypes)
  }
  if (!is.null(target_stations)) {
    summary_data <- summary_data %>% filter(stationname %in% target_stations)
  }
  
  # Create the plot with grid faceting
  p <- summary_data %>%
    mutate(biol_label = paste("BioRep", biol)) %>%
    ggplot(aes(x = biol_label, fill = species_name, y = mean_prop)) +
    geom_col(position = "stack") +
    labs(x = "Biological Replicate", 
         y = "Mean Proportion", 
         fill = "Species",
         title = "Sample Composition by Station and Sample Type") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
          strip.text = element_text(size = 9)) +
    facet_grid(sampletype ~ stationname, scales = "free_x", space = "free_x")
  
  return(p)
}


```

```{r, plotting}
# Usage examples with your new data structure:
# 1. Ridgeline plot for PvCF samples at station D1
p1 <- plot_bayes_ridges(
  posterior_data = int_samp_small_tibble,
  target_sampletype = "PvCF",
  target_station = "D1",
  time_as_factor = TRUE
)
# 2. Bar plot for specific stations
p2 <- plot_bayes_bars(
  summary_data = summary_stats, # You'll need to create this from your posterior
  target_stations = c("D1", "D2", "D3")
)

# 3. Time series for specific species at a station
# p3 <- plot_bayes_timeseries(
#  posterior_data = int_samp_small_tibble,
# target_station = "D1",
#  target_species = "Nereididae",
#  time_as_numeric = TRUE)


# Usage examples of plot_sample_composition:

# 4. Plot all PvCF samples, faceted by station
p1 <- plot_sample_composition(
  posterior_data = int_samp_small_tibble,
  target_sampletypes = "PvCF",
  facet_by_station = TRUE,
  min_proportion = 0.01
)

print(p1)

# 2. Plot both sampletypes for specific stations
#p2 <- plot_sample_composition(
#  target_sampletypes = c("PvCF", "TM"),
#  target_stations = c("D1", "D2", "D3","MktSq","GPO"),
#  facet_by_station = TRUE,
#  min_proportion = 0.01
#)

p2 <- plot_sample_composition(
  posterior_data = int_samp_small_tibble,
  target_sampletypes = "PvScat",
  facet_by_station = TRUE,
  min_proportion = 0.01
)


print(p2)

# 3. Grid plot showing both sampletype and station
#p3 <- plot_sample_composition_grid(
#  posterior_data = int_samp_small_tibble,
#  target_sampletypes = c("PvCF", "TM"),
#  target_stations = c("D1", "D2", "D3", "D4"),
#  min_proportion = 0.01
#)

# 4. Plot without faceting to see all samples together
# p4 <- plot_sample_composition(
#   posterior_data = int_samp_small_tibble,
#   target_sampletypes = "TM",
#   facet_by_station = FALSE,
#   min_proportion = 0.01
# )
p4 <- plot_sample_composition(
  posterior_data = int_samp_small_tibble,
  target_sampletypes = "TM",
  facet_by_station = TRUE,
  min_proportion = 0.01
)



print(p1)
# Save plots
ggsave(here("Figures", "CorrectionBiasRun","20250824_bayesout_ControlFeedingTMWildScats_PvCF_sample_composition.png"), p1, width = 12, height = 8)
#ggsave(here("Figures","CorrectionBiasRun", "bars_stations.png"), p2, width = 10, height = 6)
#ggsave(here("Figures", "CorrectionBiasRun","timeseries_nereididae_d1.png"), p3, width = 10, height = 6)

ggsave(here("Figures", "CorrectionBiasRun","20250824_bayesout_ControlFeedingTMWildScats_PvWildScat_sample_composition.png"), p2, width = 12, height = 8)

print(p4)
ggsave(here("Figures", "CorrectionBiasRun","20250824_bayesout_ControlFeedingTMWildScats_TM_sample_composition.png"), p4, width = 12, height = 10)

```


plotting the comparison plots
```{r}
library(here)

# Create a directory for the individual sample plots using here()
plot_dir <- here("sample_comparison_plots")
if (!dir.exists(plot_dir)) {
  dir.create(plot_dir)
}

cat(paste("Creating plots in:", plot_dir, "\n"))

# Get unique model_sample_names
unique_model_samples <- unique(input_corr_props$model_sample_name)

# Create individual plots for each model_sample_name
for (model_sample in unique_model_samples) {
  
  # Filter data for this model sample
  sample_data <- input_corr_props %>%
    filter(model_sample_name == model_sample)
  
  # Get all the original sample names (tech reps) for this model sample
  original_samples <- unique(sample_data$samplename)
  
  # Pivot longer to have both corrected and uncorrected in one column
  plot_data <- sample_data %>%
    pivot_longer(
      cols = c(uncorrected_prop, mean_prop),
      names_to = "data_type",
      values_to = "proportion"
    ) %>%
    mutate(
      data_type = factor(data_type,
                        levels = c("uncorrected_prop", "mean_prop"),
                        labels = c("Uncorrected Input", "Model Corrected"))
    )
  
  # Create the plot
  p <- ggplot(plot_data, aes(x = samplename, fill = species, y = proportion)) +
    geom_col(position = "stack") +
    labs(
      title = paste("Sample:", model_sample),
      subtitle = paste("Station:", unique(sample_data$station_original),
                      "| Type:", unique(sample_data$station_type)),
      x = "Technical Replicates",
      y = "Proportion",
      fill = "Species"
    ) +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "right"
    ) +
    scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
    facet_wrap(~data_type, ncol = 2)
  
  # Save the plot using here()
  filename <- paste0(gsub("[^[:alnum:]]", "_", model_sample), ".png")
  ggsave(here(plot_dir, filename), plot = p,
         width = 12, height = 8, units = "in", dpi = 300)
}

# Verify proportions function (unchanged)
verify_proportions <- function(input_corr_props) {
  # Check uncorrected proportions
  uncorrected_totals <- input_corr_props %>%
    group_by(samplename) %>%
    summarise(
      total_uncorrected = sum(uncorrected_prop),
      .groups = 'drop'
    )
  
  # Check corrected proportions
  corrected_totals <- input_corr_props %>%
    group_by(model_sample_name) %>%
    summarise(
      total_corrected = sum(mean_prop),
      .groups = 'drop'
    )
  
  cat("Uncorrected proportion totals (should be 1):\n")
  print(summary(uncorrected_totals$total_uncorrected))
  
  cat("\nCorrected proportion totals (should be 1):\n")
  print(summary(corrected_totals$total_corrected))
  
  # Identify any samples that don't sum to 1 (within rounding error)
  problematic_uncorrected <- uncorrected_totals %>%
    filter(abs(total_uncorrected - 1) > 0.001)
  
  problematic_corrected <- corrected_totals %>%
    filter(abs(total_corrected - 1) > 0.001)
  
  cat("\nProblematic uncorrected samples:\n")
  if (nrow(problematic_uncorrected) > 0) {
    print(problematic_uncorrected)
  } else {
    cat("All good!\n")
  }
  
  cat("\nProblematic corrected samples:\n")
  if (nrow(problematic_corrected) > 0) {
    print(problematic_corrected)
  } else {
    cat("All good!\n")
  }
}

# Verify proportions
verify_proportions(input_corr_props)

# Create a quick overview plot of a few samples to check
sample_subset <- unique_model_samples[1:6]  # First 6 samples

overview_data <- input_corr_props %>%
  filter(model_sample_name %in% sample_subset) %>%
  pivot_longer(
    cols = c(uncorrected_prop, mean_prop),
    names_to = "data_type",
    values_to = "proportion"
  ) %>%
  mutate(
    data_type = factor(data_type,
                      levels = c("uncorrected_prop", "mean_prop"),
                      labels = c("Uncorrected Input", "Model Corrected"))
  )

overview_plot <- ggplot(overview_data, aes(x = model_sample_name, fill = species, y = proportion)) +
  geom_col(position = "stack") +
  labs(
    title = "Overview: Sample Proportions Comparison",
    x = "Model Sample Name",
    y = "Proportion",
    fill = "Species"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  ) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  facet_wrap(~data_type, ncol = 2)

# Save overview plot using here()
ggsave(here("overview_comparison.png"), plot = overview_plot,
       width = 16, height = 10, units = "in", dpi = 300)

cat(paste("Created individual plots for", length(unique_model_samples), "samples in folder:", plot_dir, "\n"))
cat(paste("Overview plot saved as:", here("overview_comparison.png"), "\n"))
```

